<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Text Extraction</title>
    <link rel="stylesheet" type="text/css" href="../mvp.css">
    <style>
        .image-container {
            border: 1px solid blue;
            display: flex;
            justify-content: center;
            position: relative;
            width: 500px;
            min-width: 500px;
            max-height: 500px;
            padding: 0;
        }
        .image-wrapper { 
            border: 1px solid red;
            max-width: 100%;
            max-height: 100%;
        }
        .image {
            display: block;
            max-width: 100%;
            max-height: 100%;
        }
        .image-overlay {
            background-color: rgba(0, 128, 0, 0.143);
            /* center the canvas in the div so it
               overlaps the image in the div*/
            position: absolute;
            margin-left: auto;
            margin-right: auto;
        }
        .text-output {
            background-color: lavender;
            margin: 0 10px;
            box-sizing: border-box;
            width: 500px;
            max-height: 250px;
            overflow: auto;
        }

    </style>
</head>
<body>
    <main>
        <section>
            <form>
                <h1>Optical Character Recognition</h1>
                <label for="img">Upload image:</label>
                <input class="img-input" type="file" name="img" accept="image/*" multiple required>
                <button type="button" class="submit">Submit</button>
            </form>
        </section>
        <h1 class="jobnumber"></h1>
        <div class="main-container"></div>
    </main>

    <script>
        /* DOM elements */
        const $imgInput = document.querySelector('.img-input');
        const $submit = document.querySelector('.submit');
        const $mainContainer = document.querySelector('.main-container');
        const $jobnumber = document.querySelector('.jobnumber');

        /* Global variables */
        let jobMetaData;

        $submit.addEventListener('click', async () => {
            /* Clear the data container */
            jobMetaData = {};
            $mainContainer.innerHTML = '';

            /* Create a FormData from the selected image files */
            const files = Array.from($imgInput.files);
            if (files.length === 0) {
                return console.log('Please add a file')
            }
            const formData = new FormData();
            files.forEach(file => formData.append('userFiles', file, file.name));
            
            /* Send the images to the server */
            const res = await fetch('/image-text-extraction/api/assets', {
                method: 'POST',
                body: formData
            });
            const body = await res.json();
            const jobId = body.jobId;
            const imageUrls = body.images.map(e => {
                return `/image-text-extraction/uploads/${e.filename}`;
            });

            /* Load the images and canvas on the DOM, and an array of objects with info about the current job */
            /* [ {$imageOverlay, $textOutput, scale_factor}, ... ] */
            jobMetaData = await Promise.all(imageUrls.map(loadImageAndCanvas));

            /* Make requests to the server to get the OCR data */
            $jobnumber.innerText = jobId;
            fetchOCRDataAndUpdateDOM(jobId);
        });

        const loadImageAndCanvas = (imageUrl) => {
            return new Promise((resolve, reject) => {
                $mainContainer.insertAdjacentHTML('beforeend', `
                    <section>
                    <div class="image-container">
                    <div class="image-wrapper"><img class="image"></div>
                    <canvas class="image-overlay" hidden></canvas>
                    </div>
                    </section>
                    <section class="text-output-container">
                    <pre class="text-output"></pre>
                    </section>
                `);
                const $img = Array.from(document.querySelectorAll('.image')).pop();
                const $imageOverlay = Array.from(document.querySelectorAll('.image-overlay')).pop();
                const $textOutput = Array.from(document.querySelectorAll('.text-output')).pop();

                /* once the image loads, size the canvas to match */
                $img.onload = () => {
                    /* calculate scale factor */
                    const scale_factor = $img.width / $img.naturalWidth;
                    $imageOverlay.width = $img.width;
                    $imageOverlay.height = $img.height;
                    $imageOverlay.hidden = false;
                    resolve({$imageOverlay, $textOutput, scale_factor});
                };
                $img.src = imageUrl;
            });
        };

        const fetchOCRDataAndUpdateDOM = async (jobId, alreadyRendered) => {
            /* Fetch the current job. A job is an array; each element is data for
               an image that was processed by Tesseract OCR.. */
            const res = await fetch(`/image-text-extraction/jobs/${jobId}`)
            const job = await res.json();

            /* alreadyRendered tracks which outputs have already been added to DOM,
               so that we do not needlessly do it multiple times */
            if (alreadyRendered === undefined) {
                alreadyRendered = job.map(_ => false);
            }

            job.forEach((processedImage, i) => {
                if (alreadyRendered[i] || (processedImage.status !== 'done')) {
                    return;
                }
                alreadyRendered[i] = true;

                const $textOutput = jobMetaData[i].$textOutput; // the <pre> element
                const $imageOverlay = jobMetaData[i].$imageOverlay; // the <canvas> element
                const scale_factor = jobMetaData[i].scale_factor; // for scaling what will be drawn on the canvas
                
                /* Add the processed image's output text to the DOM */
                $textOutput.innerText = job[i].text.replace(/\n\s*\n/g, '\n');

                /* Draw the boundary boxes on the canvas */
                const ctx = $imageOverlay.getContext("2d");
                processedImage.ocr_data.forEach(e => {
                    const left = e.left * scale_factor;
                    const top = e.top * scale_factor;
                    const width = e.width * scale_factor;
                    const height = e.height * scale_factor;
                    ctx.beginPath();
                    ctx.lineWidth = '0.5';
                    ctx.strokeStyle = 'red';
                    ctx.rect(left, top, width, height);
                    ctx.stroke();
                });
            });

            /* All images are processed */
            if (alreadyRendered.every(e => e === true)) {
                console.log('JOB IS DONE')
                return;
            }

            /* Repeat until all outputs are displayed on DOM */
            setTimeout(() => {
                fetchOCRDataAndUpdateDOM(jobId, alreadyRendered);
            }, 1000);
        };
    </script>
</body>
</html>